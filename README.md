# Visual-Explanations-for-Spatio-temporal-Networks


Hi, here I am storing all the articles and works that are related to explainable artificial intelligence and video data :hugs:





**3D-CNN**
:desktop_computer: Repositories 
1. Visually explaining 3D-CNN predictions for video classification with an adaptive occlusion sensitivity analysis
   https://github.com/uchiyama33/AOSA

2.  Grad-CAM-for-video-and-regression-task
https://github.com/UtopAIBuilder/Grad-CAM-for-video-and-regression-task

3. Spatio-Temporal-Perturbations-for-Video-Attribution
https://github.com/shinkyo0513/Spatio-Temporal-Perturbations-for-Video-Attribution

:writing_hand: Articles 


   
      
      //2024//
   **1. Gaya-Morey, F. Xavier et al. “Local Agnostic Video Explanations: a Study on the Applicability of Removal-Based Explanations to Video.” (2024).**
      https://www.semanticscholar.org/paper/Local-Agnostic-Video-Explanations%3A-a-Study-on-the-Gaya-Morey-Buades-Rubio/ec8f1b25935904e8866d51d93e27ce0894e324a4
      
      The key results of this paper include the adaptation of six explanation techniques for video data, the evaluation and comparison of these methods using different models and datasets, and the finding that 3D RISE, 3D LIME, and 3D Kernel SHAP outperform other methods.
      
      //2023//
      
   **1. Gulshad, Sadaf et al. “Hierarchical Explanations for Video Action Recognition.” 2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW) (2023): 3703-3708.**
      https://www.semanticscholar.org/paper/Hierarchical-Explanations-for-Video-Action-Gulshad-Long/8aa729cff93d270bab251ece1db8044bcb7318c9
      
      
      The goal of this paper is to propose a model called HIPE (Hierarchical Prototype Explainer) for video action recognition that provides multi-level explanations by learning hierarchical prototypes.
      
      The key results of this paper are that the proposed Hierarchical Prototype Explainer (HIPE) outperforms a non-hierarchical approach on the UCF-101 dataset and performs equally well on the ActivityNet dataset. HIPE provides multi-level explanations, allowing for a deeper understanding of the spatiotemporal parts that contribute to different levels of classification.
      
      //2022//
      
   **1. Hartley, Thomas et al. “SWAG-V: Explanations for Video using Superpixels Weighted by Average Gradients.” 2022 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) (2022): 1576-1585.**
      https://www.semanticscholar.org/paper/SWAG-V%3A-Explanations-for-Video-using-Superpixels-by-Hartley-Sidorov/414bfba7768b9f44ea53be05647d9a7e913eb354#citing-papers
      
      
   **2. Ji, Yi et al. “Spatial-temporal Concept based Explanation of 3D ConvNets.” 2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) (2022): 15444-15453.**
      https://www.semanticscholar.org/paper/Spatial-temporal-Concept-based-Explanation-of-3D-Ji-Wang/4f9e122682617710546ce5beaba02778c098bbc3
      
      The goal of this paper is to propose a 3D ACE (Automatic Concept-based Explanation) framework for interpreting 3D ConvNets in video recognition. The framework aims to discover spatial-temporal concepts of different importance levels and explore their influence on a target task, such as action classification.
      
      The key results of this paper include the development of a 3D ACE framework for interpreting 3D ConvNets, the discovery of spatial-temporal concepts of different importance levels, and the exploration of the influence of these concepts on a target task, such as action classification.

      https://github.com/alexandrosstergiou/Saliency-Tubes-Visual-Explanations-for-Spatio-Temporal-Convolutions
      
      //2021//
      
   **1. Li, Zhenqiang et al. “Towards Visually Explaining Video Understanding Networks with Perturbation.” 2021 IEEE Winter Conference on Applications of Computer Vision (WACV) (2020): 1119-1128.**
      
      [https://arxiv.org/pdf/2401.10831.pdf](https://www.semanticscholar.org/paper/Understanding-Video-Transformers-via-Universal-Kowal-Dave/f717c3581620b198fc22b5f5bd946286f4ab1e0b)
         
   **2.Li, Zhenqiang et al. “Towards Visually Explaining Video Understanding Networks with Perturbation.” 2021 IEEE Winter Conference on Applications of Computer Vision (WACV) (2020): 1119-1128.**
      https://www.semanticscholar.org/paper/Towards-Visually-Explaining-Video-Understanding-Li-Wang/b9338b7de4b849cb094aa4cbd5b85f9935a4ae00
      
      //2019//
      
   **3. Stergiou, Alexandros et al. “Saliency Tubes: Visual Explanations for Spatio-Temporal Convolutions.” 2019 IEEE International Conference on Image Processing (ICIP) (2019): 1830-1834.**
      https://www.semanticscholar.org/paper/Saliency-Tubes%3A-Visual-Explanations-for-Stergiou-Kapidis/7a307c21fdd9a3edff092fe0485399714e53fd7a#citing-papers
      
      The methods used in the paper are Saliency Tubes, a generalized attention mechanism for explaining CNN decisions, and 3D Convolutional Neural Networks (CNNs) for video classification and recognition.
      
      The key results of this paper are the proposal of Saliency Tubes as a method to visualize the activation maps of 3D CNNs, the demonstration of Saliency Tubes on existing video recognition models for action classification and egocentric action recognition, and the improvement of interpretability of 3D CNNs by revealing the spatio-temporal regions that are most informative for predicting action classes.


**Transformers**

:desktop_computer: Repositories
1. Transformer-Explainability  https://github.com/hila-chefer/Transformer-Explainability
Implementation of https://arxiv.org/abs/2012.09838 Transformer Interpretability Beyond Attention Visualization

2. Transformer-Explainability https://github.com/hila-chefer/Transformer-Explainability?tab=readme-ov-file
ViT explainability for images


**XAI Methods**
:star2: *Grad-CAM*

:desktop_computer: Repositories
1. A Simple pytorch implementation of GradCAM and GradCAM++ (for Images)
   https://github.com/1Konny/gradcam_plus_plus-pytorch
2. pytorch-grad-cam
   https://github.com/jacobgil/pytorch-grad-cam
3. Grad_CAM_plus_plus
   https://github.com/adityac94/Grad_CAM_plus_plus
4. Class activation maps for your PyTorch models (CAM, Grad-CAM, Grad-CAM++, Smooth Grad-CAM++, Score-CAM, SS-CAM, IS-CAM, XGrad-CAM, Layer-CAM) 
   https://github.com/frgfm/torch-cam

:star2: *Other*
1.A toolbox to iNNvestigate neural networks' predictions! 
https://github.com/albermax/innvestigate?tab=readme-ov-file#usage-and-examples

**Video**
1. OpenMMLab's Next Generation Video Understanding Toolbox and Benchmark 
https://github.com/open-mmlab/mmaction2
2. 3D-Machine-Learning
https://github.com/timzhang642/3D-Machine-Learning

**Survey Papers for XAI and/or medicine**

1. Official repository of the paper "Explainable Deep Learning Methods in Medical Image Classification: A Survey", ACM Computing Surveys (CSUR) 2023 
https://github.com/CristianoPatricio/Explainable-Deep-Learning-Methods-in-Medical-Image-Classification-A-Survey

2. Surgical-Phase-Recognition
 https://github.com/maxboels/Surgical-Phase-Recognition


