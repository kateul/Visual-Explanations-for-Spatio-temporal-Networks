# Visual-Explanations-for-Spatio-temporal-Networks


Hi, here I am storing all the articles and works that are related to explainable artificial intelligence and video data :hugs:


Работы за 2024 год


Работа с изображениями 

ТРАНСФОРМЕРЫ

Статьи ✍

1. Understanding Video Transformers via Universal Concept Discovery https://arxiv.org/pdf/2401.10831.pdf
   
Суть: 

Репозитории:
1. Transformer-Explainability  https://github.com/hila-chefer/Transformer-Explainability
Implementation of https://arxiv.org/abs/2012.09838 Transformer Interpretability Beyond Attention Visualization



Работа с видео

Статьи
1. Stergiou, Alexandros et al. “Saliency Tubes: Visual Explanations for Spatio-Temporal Convolutions.” 2019 IEEE International Conference on Image Processing (ICIP) (2019): 1830-1834.
https://www.semanticscholar.org/paper/Saliency-Tubes%3A-Visual-Explanations-for-Stergiou-Kapidis/7a307c21fdd9a3edff092fe0485399714e53fd7a#citing-papers

The methods used in the paper are Saliency Tubes, a generalized attention mechanism for explaining CNN decisions, and 3D Convolutional Neural Networks (CNNs) for video classification and recognition.

The key results of this paper are the proposal of Saliency Tubes as a method to visualize the activation maps of 3D CNNs, the demonstration of Saliency Tubes on existing video recognition models for action classification and egocentric action recognition, and the improvement of interpretability of 3D CNNs by revealing the spatio-temporal regions that are most informative for predicting action classes.

2. Gaya-Morey, F. Xavier et al. “Local Agnostic Video Explanations: a Study on the Applicability of Removal-Based Explanations to Video.” (2024).
https://www.semanticscholar.org/paper/Local-Agnostic-Video-Explanations%3A-a-Study-on-the-Gaya-Morey-Buades-Rubio/ec8f1b25935904e8866d51d93e27ce0894e324a4

The key results of this paper include the adaptation of six explanation techniques for video data, the evaluation and comparison of these methods using different models and datasets, and the finding that 3D RISE, 3D LIME, and 3D Kernel SHAP outperform other methods.

3. Gulshad, Sadaf et al. “Hierarchical Explanations for Video Action Recognition.” 2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW) (2023): 3703-3708.
https://www.semanticscholar.org/paper/Hierarchical-Explanations-for-Video-Action-Gulshad-Long/8aa729cff93d270bab251ece1db8044bcb7318c9


The goal of this paper is to propose a model called HIPE (Hierarchical Prototype Explainer) for video action recognition that provides multi-level explanations by learning hierarchical prototypes.

The key results of this paper are that the proposed Hierarchical Prototype Explainer (HIPE) outperforms a non-hierarchical approach on the UCF-101 dataset and performs equally well on the ActivityNet dataset. HIPE provides multi-level explanations, allowing for a deeper understanding of the spatiotemporal parts that contribute to different levels of classification.

